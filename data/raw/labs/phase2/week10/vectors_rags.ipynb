{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44a8f8b",
   "metadata": {},
   "source": [
    "# Vector Databases & RAGs Code-Along\n",
    "\n",
    "While the pre-trained weights of most LLMs provide a great baseline for natural language, and even \"intelligent\" behavior, requests for contextual/granular information often fall flat on their face.\n",
    "\n",
    "For this reason, we must utilize vector databases & RAGs to imbue contextual information in our models. Follow along with the code below to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b36c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (4.55.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (0.34.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from transformers) (2025.7.33)\n",
      "Requirement already satisfied: requests in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saidmf\\anaconda3\\envs\\ds\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaf16b",
   "metadata": {},
   "source": [
    "## Vector Database\n",
    "\n",
    "A vector database is a specialized system for storing and searching numerical vectors efficiently. Each vector usually represents a piece of unstructured data after being processed by an embedding model (think back to `word2vec` or the `audio2vec` models we worked with).\n",
    "\n",
    "Instead of searching by keywords, a vector DB lets you search by semantic similarity. That is, we extract information that is not only **directly** related to our input prompt, but also information that **might** be related to our prompt (think back to cosine similarity).\n",
    "\n",
    "We create a vector database by storing embeddings of the information we want our model to be aware of. This could be:\n",
    "* legal documents\n",
    "* copyrighted music\n",
    "* or even pdf's of lecture slides\n",
    "\n",
    "And one of the best parts is that if we use a private implementation of a vector database, we also don't have to share information with `Meta`, `Amazon`, `Microsoft` or any other large organization that would want to sniff around our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fc6cb",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented-Generation (RAG)\n",
    "\n",
    "Retrieval-Augmented Generation is a *technique* to improve an LLM's responses by:\n",
    "* Retrieving relevant documents from a knowledge store (such a vector DB).\n",
    "* Augmenting the model's prompt with those documents.\n",
    "* Generating an answer using the model with this extra context.\n",
    "\n",
    "With RAG, the model is handed the right documents at generation time. That is, the model does not respond to a user's queries until it refers to a specified set of documents. \n",
    "\n",
    "The vector DB acts as the \"memory\" that stores your domain knowledge, whereast the RAG pipeline is the \"brain\" that searches the vector DB for relevant content, combines the top result into the user prompt, and feeds all information into the main LLM.\n",
    "\n",
    "For example, let's explore our `distilgpt2` model again. As we recall, its' basic functionalities are comparable to a hamsters' at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "479024ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"distilgpt2\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2809c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first president of the United States was __________ in 1933, the second was in 1925\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The first president of the United States was \"\n",
    "\n",
    "out = pipe(prompt, max_new_tokens=10, do_sample=True, temperature=1.0)\n",
    "print(out[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcd6dda",
   "metadata": {},
   "source": [
    "However, by giving the model a set of information which it can call back to using vector databases, we can improve its response.\n",
    "\n",
    "First, we specify a list of relevant historical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "59ea04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = [\n",
    "    \"First president: George Washington served 1789–1797; no formal party.\",\n",
    "    \"Second president: John Adams served 1797–1801; Federalist.\",\n",
    "    \"Third president: Thomas Jefferson served 1801–1809; Democratic-Republican.\",\n",
    "    \"Sixteenth president: Abraham Lincoln served 1861–1865; Republican; led the Union during the Civil War.\",\n",
    "    \"Twenty-sixth: Theodore Roosevelt served 1901–1909; Republican.\",\n",
    "    \"Thirty-second: Franklin D. Roosevelt served 1933–1945; Democratic; led during the Great Depression and WWII.\",\n",
    "    \"Thirty-fourth: Dwight D. Eisenhower served 1953–1961; Republican.\",\n",
    "    \"Thirty-fifth: John F. Kennedy served 1961–1963; Democratic; succeeded by Lyndon B. Johnson after his assassination.\",\n",
    "    \"Thirty-sixth: Lyndon B. Johnson served 1963–1969; Democratic.\",\n",
    "    \"Thirty-seventh: Richard Nixon served 1969–1974; Republican.\",\n",
    "    \"Thirty-eigth: Gerald Ford served 1974–1977; Republican.\",\n",
    "    \"Thirty-ninth: Jimmy Carter served 1977–1981; Democratic.\",\n",
    "    \"Fortieth: Ronald Reagan served 1981–1989; Republican.\",\n",
    "    \"Forty-first: George H. W. Bush served 1989–1993; Republican.\",\n",
    "    \"Forty-second: Bill Clinton served 1993–2001; Democratic.\",\n",
    "    \"Forty-third: George W. Bush served 2001–2009; Republican.\",\n",
    "    \"Forty-fourth: Barack Obama served 2009–2017; Democratic.\",\n",
    "    \"Forty-fifth: Donald Trump served 2017–2021; Republican.\",\n",
    "    \"Forty-sixth: Joe Biden began 2021; Democratic.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a57421",
   "metadata": {},
   "source": [
    "Now that we have a prepared set of facts that we want the model to \"remember\", we convert all of these sentences into embeddings which can then be used to inform the model. We use the [SentenceTransformer](https://sbert.net/) object to convert all these sentences into vector embeddings which will then be stored on the [Facebook AI Similarity Search](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) (`FAISS`) which provides efficient similarity search & clustering of dense vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "02930c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 768)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss     \n",
    "\n",
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "embeddings = embedder.encode(facts, normalize_embeddings=True) \n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3612e3",
   "metadata": {},
   "source": [
    "Note that we retain the length of our original 'facts' list (19). However this time, we also have 768 additional dimensions which express some sort of semantic meaning of the sentence.\n",
    "\n",
    "We could utilize this list of vector embeddings to find similar/disimilar facts. Let's envision a user trying to find more information on Ronald Reagan. They begin their prompt with \"Ronald Reagan was a...\" which we could express as a vector of 768 dimensions using our transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "17e9ad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.82279221e-03,  1.82359405e-02,  5.11318482e-02,\n",
       "         3.68423387e-03,  1.70134883e-02, -4.15227488e-02,\n",
       "        -7.91858360e-02,  5.28977625e-02, -4.34197932e-02,\n",
       "         1.13973329e-02,  9.66298208e-03,  6.25337288e-02,\n",
       "         4.50947322e-03,  5.83700426e-02,  1.53515243e-03,\n",
       "        -1.72120556e-02, -5.39328121e-02,  1.09018404e-02,\n",
       "        -2.22240612e-02, -6.65859925e-03, -8.64041783e-03,\n",
       "         5.65448776e-02, -2.01766137e-02, -1.77255347e-02,\n",
       "         3.94262969e-02,  2.72729341e-03,  9.84456390e-03,\n",
       "        -1.17754459e-01,  5.83857857e-02,  1.01187946e-02,\n",
       "        -3.07621136e-02,  1.46105932e-02, -8.37213174e-03,\n",
       "         1.85176712e-02, -9.66928806e-03, -7.75542622e-03,\n",
       "         2.88648978e-02,  4.66978783e-03, -1.03346794e-03,\n",
       "         2.77778916e-02,  7.33339787e-02, -3.56054530e-02,\n",
       "         1.89625546e-02,  4.44491208e-02, -4.00660485e-02,\n",
       "        -3.41446549e-02, -3.33153439e-04,  5.46278767e-02,\n",
       "         3.67420726e-02, -1.54714942e-01, -3.28307152e-02,\n",
       "        -3.95028442e-02, -2.56838351e-02,  4.36623134e-02,\n",
       "        -2.43174043e-02,  4.47652787e-02,  2.82187909e-02,\n",
       "        -2.91772652e-02,  1.43140601e-02,  8.28633178e-03,\n",
       "         5.89251099e-03, -2.13687941e-02,  3.45432460e-02,\n",
       "         6.57021720e-03, -2.98060104e-02,  2.30153799e-02,\n",
       "         1.88882258e-02,  2.62364931e-02, -2.54301541e-02,\n",
       "         6.94323983e-03, -1.35002453e-02, -3.88129391e-02,\n",
       "        -3.94892730e-02, -1.13096870e-02, -2.63022352e-02,\n",
       "         2.69105323e-02,  1.00081647e-02,  1.94345582e-02,\n",
       "         4.31747325e-02, -3.35122794e-02,  1.13532804e-02,\n",
       "         1.58646964e-02,  4.85014021e-02,  4.82078977e-02,\n",
       "        -2.45951135e-02,  3.36801540e-03, -4.81406553e-03,\n",
       "         1.24507826e-02, -2.22302414e-02, -7.71052158e-03,\n",
       "        -3.41641977e-02,  3.24434415e-02,  3.05449385e-02,\n",
       "        -4.61162580e-03,  1.18234018e-02, -4.59844396e-02,\n",
       "         4.96348441e-02, -7.04308823e-02,  1.46680241e-02,\n",
       "        -2.61194017e-02,  1.24033890e-03, -8.31728615e-03,\n",
       "        -2.25032009e-02, -7.93871190e-03, -2.12954953e-02,\n",
       "        -8.45068973e-03,  1.80952030e-03, -3.15487497e-02,\n",
       "         3.68066579e-02,  1.96662731e-02,  1.46676358e-02,\n",
       "         1.84618235e-02,  2.95881201e-02,  2.02808417e-02,\n",
       "        -2.62102392e-02, -7.68549461e-03, -4.06554155e-02,\n",
       "        -8.75180680e-03,  6.93178130e-03,  4.86714393e-02,\n",
       "         1.04600713e-02,  7.07549453e-02, -4.10261825e-02,\n",
       "        -3.16488370e-02,  4.25427817e-02,  7.25132937e-04,\n",
       "         2.69974153e-02,  2.27672104e-02, -1.04815640e-01,\n",
       "        -1.43064652e-02, -2.72828341e-02,  2.61481106e-02,\n",
       "         1.58414803e-02, -3.10219708e-03, -3.50403483e-03,\n",
       "         3.04136984e-02,  1.32889310e-02, -1.66007243e-02,\n",
       "        -4.52495413e-03,  3.38938050e-02,  4.80996305e-03,\n",
       "         1.28471460e-02,  4.10363562e-02, -3.65330502e-02,\n",
       "         4.19028513e-02, -4.27483954e-03,  6.50125146e-02,\n",
       "        -1.40452897e-02,  2.32244073e-03,  1.90075729e-02,\n",
       "        -1.93391778e-02, -2.61628255e-02,  3.34091671e-02,\n",
       "         1.55474208e-02, -5.42100035e-02, -1.82053745e-02,\n",
       "        -1.88942868e-02,  1.42621743e-02,  3.50987129e-02,\n",
       "         1.21880202e-02, -4.54577385e-03, -3.46592702e-02,\n",
       "        -6.67161914e-03, -1.24274213e-02,  2.70681437e-02,\n",
       "        -1.62162315e-02,  3.75355966e-02, -7.15237518e-04,\n",
       "        -3.85464216e-03,  1.45172030e-02,  9.54343658e-03,\n",
       "         2.62146234e-03,  4.92572300e-02,  1.71664208e-02,\n",
       "         5.32103814e-02,  5.29057384e-02,  3.54134440e-02,\n",
       "         2.94296127e-02, -2.67609418e-03,  1.62877236e-02,\n",
       "        -3.42768268e-03, -2.31343647e-03, -3.83854355e-03,\n",
       "        -5.25072357e-03,  2.43008770e-02, -1.29059199e-02,\n",
       "        -2.05209553e-02, -2.78617926e-02,  5.92027605e-02,\n",
       "         4.56033945e-02, -1.06869796e-02, -5.51225878e-02,\n",
       "        -7.58222938e-02, -4.74327281e-02,  6.19705394e-02,\n",
       "        -9.00605973e-03,  1.11840414e-02, -1.63480882e-02,\n",
       "        -2.70144995e-02, -2.64601633e-02,  2.47638151e-02,\n",
       "        -6.03987239e-02,  3.18173170e-02, -1.30271865e-03,\n",
       "        -4.59026918e-02,  2.23828908e-02, -9.54967272e-03,\n",
       "        -2.29537999e-03,  6.01680810e-03, -6.88306149e-03,\n",
       "        -2.05643158e-02,  6.76079988e-02,  1.24554224e-02,\n",
       "         1.65395450e-03,  4.27780626e-03,  2.13768668e-02,\n",
       "         5.42464703e-02,  4.92211841e-02, -9.33044180e-02,\n",
       "         6.73869923e-02, -1.18135596e-02,  4.04483862e-02,\n",
       "         9.84913204e-04,  5.12134060e-02, -4.47997898e-02,\n",
       "         6.38795346e-02,  2.92262714e-02, -7.37692267e-02,\n",
       "        -9.89779532e-02,  5.12209497e-02,  4.70953807e-02,\n",
       "        -2.73974035e-02, -4.07650555e-03,  5.98476455e-02,\n",
       "        -2.76868399e-02,  2.08612182e-03, -5.78021631e-02,\n",
       "        -3.34679484e-02, -2.51770746e-02,  3.48244881e-04,\n",
       "        -1.67940650e-02,  2.93521043e-02,  8.37429054e-03,\n",
       "         2.12759487e-02, -7.33187348e-02, -2.26401649e-02,\n",
       "         1.25060678e-02, -1.47438804e-02,  2.12283563e-02,\n",
       "         3.75158302e-02, -4.00194526e-02, -7.76794925e-02,\n",
       "         6.36187494e-02, -2.77928542e-02, -1.54168727e-02,\n",
       "        -3.18567567e-02,  7.48397084e-04,  4.51900847e-02,\n",
       "         1.95063911e-02, -9.30263195e-03, -3.70159596e-02,\n",
       "        -7.40894452e-02, -3.55848819e-02,  2.18572244e-02,\n",
       "        -3.24458182e-02, -4.00950052e-02,  2.64405943e-02,\n",
       "         2.44505610e-02, -5.42923324e-02,  1.09304683e-02,\n",
       "        -4.01724763e-02, -6.72008051e-03, -3.47751118e-02,\n",
       "         2.21934868e-03,  3.19010466e-02, -4.64901440e-02,\n",
       "         1.98359042e-02,  2.94028204e-02, -2.92033274e-02,\n",
       "        -4.19848599e-04,  5.31399399e-02,  2.58044396e-02,\n",
       "        -1.13377184e-01,  2.79734209e-02, -4.47941050e-02,\n",
       "         2.07839552e-02, -1.45801436e-02, -5.33824489e-02,\n",
       "         9.92157776e-03, -1.62217654e-02, -1.91085283e-02,\n",
       "        -4.83560190e-03, -6.88340282e-04, -3.48997749e-02,\n",
       "         1.24820182e-02,  4.15454879e-02,  9.10496339e-03,\n",
       "         4.84177945e-05, -9.16334242e-03,  1.09574432e-02,\n",
       "        -5.96863031e-03,  9.68763418e-03, -3.14296968e-02,\n",
       "         8.51624161e-02,  4.13827375e-02, -5.73889874e-02,\n",
       "        -2.13689897e-02,  1.56174973e-03, -2.55075227e-02,\n",
       "         2.97171120e-02, -5.48019148e-02, -6.46371171e-02,\n",
       "         7.24180462e-03,  5.89384548e-02, -1.78700201e-02,\n",
       "         7.87942990e-05, -3.51042300e-02,  4.75267088e-03,\n",
       "        -3.86751047e-03, -5.02679609e-02, -2.36365106e-02,\n",
       "         4.60146517e-02, -4.33682417e-03,  5.12749292e-02,\n",
       "         3.66320610e-02, -5.22997370e-03, -3.41062844e-02,\n",
       "         3.15211155e-02,  2.11679917e-02, -2.34201197e-02,\n",
       "         4.83795926e-02, -2.55480967e-02,  7.79355410e-03,\n",
       "         2.24538203e-02,  4.51495759e-02,  5.42929675e-03,\n",
       "         1.06243091e-02, -2.38656886e-02,  4.22782041e-02,\n",
       "         7.69455219e-03,  4.28497717e-02, -3.50873321e-02,\n",
       "        -1.82442926e-02,  4.36711721e-02,  4.88910228e-02,\n",
       "        -3.66768949e-02,  4.10056161e-03, -7.13562360e-03,\n",
       "         1.91208441e-02, -1.31135890e-02,  2.31337920e-02,\n",
       "         1.48513000e-02,  3.56110260e-02, -6.47469144e-03,\n",
       "        -4.54999506e-02, -4.91327569e-02, -3.88982967e-02,\n",
       "        -1.22093707e-02, -3.29982117e-02,  9.14221630e-02,\n",
       "        -1.61424410e-02, -2.74449829e-02, -9.29039717e-03,\n",
       "         2.35646982e-02, -4.29877304e-02,  4.02142629e-02,\n",
       "         1.05943857e-02, -1.10336266e-01,  5.30999936e-02,\n",
       "         7.10894689e-02,  5.75633571e-02,  5.19983247e-02,\n",
       "        -6.05857782e-02, -1.10385716e-02,  4.05382644e-03,\n",
       "         1.83750596e-02,  7.01941624e-02, -1.16425361e-02,\n",
       "        -8.91944580e-03,  4.36209999e-02,  3.46911773e-02,\n",
       "        -5.90240695e-02,  1.13976495e-02, -3.83336693e-02,\n",
       "        -3.14413421e-02,  4.05881293e-02, -7.03837068e-05,\n",
       "         4.59554903e-02, -1.01219704e-02,  3.25318351e-02,\n",
       "        -6.01960253e-03,  5.13248704e-02,  2.00792793e-02,\n",
       "         3.94061133e-02, -2.29760837e-02, -2.52594277e-02,\n",
       "         5.78903630e-02,  2.36573610e-02, -7.35106319e-03,\n",
       "         4.40007215e-03, -1.11226225e-02,  5.11911232e-03,\n",
       "         3.15500423e-02, -2.11675297e-02,  5.26337475e-02,\n",
       "         3.92580517e-02,  8.39564279e-02,  3.10695078e-03,\n",
       "        -2.91663967e-03, -8.19877069e-03,  3.70302121e-03,\n",
       "        -4.50765416e-02, -1.13649564e-02,  4.65331459e-03,\n",
       "        -2.18949635e-02,  1.80718489e-02, -2.56371889e-02,\n",
       "        -2.70599369e-02,  1.47230364e-02,  3.91580816e-03,\n",
       "         2.63046976e-02, -6.35757446e-02,  3.39646377e-02,\n",
       "         5.14519401e-03, -1.01131527e-02,  7.72309452e-02,\n",
       "        -7.90158287e-03,  1.22013008e-02, -4.48564105e-02,\n",
       "         5.00723459e-02, -3.34435031e-02, -5.14959581e-02,\n",
       "        -5.19969910e-02, -1.05777662e-02, -3.57500948e-02,\n",
       "        -8.19585174e-02, -2.34517809e-02, -2.62565427e-02,\n",
       "         1.59915015e-02,  3.59397684e-03,  2.98724119e-02,\n",
       "         1.73795801e-02,  1.30494898e-02,  8.90212657e-04,\n",
       "        -1.28399851e-02, -1.02733374e-02,  1.70392655e-02,\n",
       "         5.88534810e-02,  6.55937986e-03, -3.83114554e-02,\n",
       "         2.94345227e-04, -3.28109111e-03, -1.68607980e-02,\n",
       "         8.79464950e-03,  5.39046153e-03,  2.86186617e-02,\n",
       "         9.09117516e-03, -6.10367060e-02,  1.68589130e-03,\n",
       "        -2.55986713e-02, -5.74902119e-03, -3.87537330e-02,\n",
       "        -6.56400472e-02, -2.92058699e-02,  2.01951116e-02,\n",
       "        -2.25796830e-03, -7.18561113e-02, -3.97744961e-02,\n",
       "        -2.76505575e-02, -1.36354016e-02,  3.13548446e-02,\n",
       "        -1.89638678e-02,  3.73972617e-02,  1.25098526e-02,\n",
       "         7.28297234e-03, -4.46596630e-02, -1.36392156e-03,\n",
       "         7.25341737e-02, -1.90438721e-02,  2.30360087e-02,\n",
       "        -2.38263737e-02,  6.06143661e-03, -1.05627440e-02,\n",
       "         5.67102507e-02,  1.45042809e-02, -6.55832291e-02,\n",
       "         1.46733345e-02, -2.33193133e-02,  1.54737839e-02,\n",
       "        -3.39030810e-02, -9.77338552e-02, -4.73372377e-02,\n",
       "        -4.44921516e-02, -1.00129604e-01, -4.32269946e-02,\n",
       "         3.58357430e-02, -6.66634887e-02, -3.46402116e-02,\n",
       "         5.63308820e-02,  2.22151866e-03, -3.11447438e-02,\n",
       "        -1.43949464e-02, -8.12291820e-03, -1.94077361e-02,\n",
       "         7.01702025e-04, -1.80371460e-02,  9.58214048e-03,\n",
       "        -9.54779796e-03, -2.06190292e-02,  2.29455554e-03,\n",
       "        -5.30491173e-02,  3.62627096e-02, -5.56101277e-02,\n",
       "        -2.82612909e-02, -9.51953232e-02, -6.17215503e-03,\n",
       "         1.81627052e-03,  3.99628580e-02,  4.82862769e-03,\n",
       "        -3.38247232e-02, -1.27091119e-02, -1.59352217e-02,\n",
       "         6.88016266e-02,  5.99975660e-02, -9.11797490e-03,\n",
       "         1.96952950e-02,  1.54787744e-03, -1.63119603e-02,\n",
       "         3.33303120e-03, -5.72643727e-02, -3.38760838e-02,\n",
       "        -7.69318175e-03,  1.29981106e-02,  3.48216631e-02,\n",
       "         5.64700961e-02, -2.06273291e-02, -1.40986331e-02,\n",
       "        -7.45553598e-02, -3.63521315e-02,  7.77905248e-03,\n",
       "         2.73424573e-02,  2.53238138e-02,  5.26729822e-02,\n",
       "         8.01494997e-03, -2.68250778e-02,  1.75643079e-02,\n",
       "         2.15802193e-02,  5.58202519e-05, -1.71627253e-02,\n",
       "        -4.01378563e-03, -3.87782753e-02, -1.46728978e-02,\n",
       "        -3.72575559e-02, -1.50021547e-02,  3.90660278e-02,\n",
       "        -2.11678818e-03,  2.20596138e-03,  3.86237986e-02,\n",
       "        -1.71492379e-02, -3.32608595e-02,  2.39249896e-02,\n",
       "         1.40112666e-02,  3.34148668e-03, -5.74312881e-02,\n",
       "        -3.01504489e-02,  2.64040511e-02, -1.80427078e-02,\n",
       "        -4.31879796e-02, -3.96143794e-02, -4.22360823e-02,\n",
       "         1.31721860e-02,  1.52842316e-03,  1.42237544e-02,\n",
       "         5.18789738e-02, -7.93792587e-03,  5.87638542e-02,\n",
       "         8.58258307e-02,  1.06345292e-03, -5.87025173e-02,\n",
       "        -2.51975525e-02,  2.88029462e-02,  6.75346553e-02,\n",
       "        -7.71803502e-03, -1.93135533e-02, -3.31361368e-02,\n",
       "         2.02028211e-02, -3.89784039e-03, -7.03632161e-02,\n",
       "         6.55935332e-03,  9.02768299e-02,  3.40350419e-02,\n",
       "        -5.75364307e-02, -2.39451118e-02, -6.21186830e-02,\n",
       "        -4.24802229e-02,  4.29026736e-03, -1.87007096e-02,\n",
       "         4.47553732e-02, -2.63997167e-02, -7.88595155e-03,\n",
       "         4.27028202e-02, -8.69535804e-02, -5.56605347e-02,\n",
       "         4.50775884e-02, -2.27648783e-02,  1.67123079e-02,\n",
       "        -8.86880755e-02,  1.40200350e-02, -2.60897409e-02,\n",
       "         3.44799645e-02, -2.52274778e-02, -4.13068496e-02,\n",
       "        -8.65698140e-03,  1.40818255e-02, -1.31201874e-02,\n",
       "        -5.50810471e-02, -3.39866914e-02,  4.16609421e-02,\n",
       "         5.71184233e-03, -1.37155103e-02,  5.31543978e-03,\n",
       "         2.54951715e-02, -5.11822514e-02, -5.12920786e-03,\n",
       "         1.69403646e-02, -2.55953409e-02,  1.60825830e-02,\n",
       "        -1.94205903e-02, -2.40552928e-02,  6.03284165e-02,\n",
       "         2.68485174e-02, -3.28575703e-03,  3.03591602e-02,\n",
       "         4.88835899e-03,  3.17296991e-03,  5.12597337e-02,\n",
       "        -3.42692286e-02, -2.11735778e-02, -4.00942378e-03,\n",
       "        -1.00784944e-02, -2.38377880e-02,  6.55191094e-02,\n",
       "         5.78473285e-02, -3.97634804e-02,  4.97834496e-02,\n",
       "        -3.80216055e-02, -1.22196870e-02,  5.21251261e-02,\n",
       "         2.85509340e-02,  3.90628353e-02,  2.33000834e-02,\n",
       "         7.41382828e-03, -2.79808361e-02,  1.91732496e-02,\n",
       "         1.21654589e-02, -9.41469043e-04,  2.08519939e-02,\n",
       "        -6.85305754e-03,  3.63183841e-02,  1.02381278e-02,\n",
       "         1.06118363e-03, -8.33549574e-02,  6.71094470e-03,\n",
       "        -8.15906841e-03,  2.00544354e-02,  3.76995616e-02,\n",
       "         7.87914265e-03, -7.97148678e-04,  4.15045731e-02,\n",
       "         1.91430617e-02,  4.99731768e-03, -3.50505635e-02,\n",
       "         8.63716602e-02, -3.45025994e-02, -1.82660464e-02,\n",
       "        -1.22976620e-02,  7.41627114e-03,  3.29041965e-02,\n",
       "        -2.72192527e-03, -5.89347109e-02,  5.76279685e-02,\n",
       "        -2.62538362e-02, -3.46962363e-03,  1.48192765e-02,\n",
       "        -2.89263669e-02, -1.26689412e-02,  2.94065755e-03,\n",
       "         4.64961194e-02, -1.80680323e-02, -1.34676900e-02,\n",
       "        -5.43319015e-03,  3.62834334e-02, -3.17589156e-02,\n",
       "        -8.36407840e-02,  4.44521792e-02,  7.04605728e-02,\n",
       "         1.44563336e-02, -3.72526608e-02,  7.42638782e-02,\n",
       "        -2.51878295e-02, -6.97127357e-02,  3.13631184e-02,\n",
       "        -1.13053545e-02, -5.01681864e-02,  1.72372144e-02,\n",
       "        -3.81294526e-02, -1.27826976e-02, -4.91737947e-02,\n",
       "         1.04587404e-02,  1.33471014e-02, -2.09287815e-02,\n",
       "         3.43980007e-02,  5.90129308e-02,  7.77327456e-03,\n",
       "        -1.05706370e-02,  6.07741512e-02,  3.67241986e-02,\n",
       "         2.36349870e-02, -1.94403324e-02, -9.93828923e-02,\n",
       "        -5.85237667e-02, -1.88066438e-02, -1.01603810e-02,\n",
       "         5.12875952e-02, -2.82834116e-02, -1.96944736e-02,\n",
       "         3.06157209e-02, -1.00598019e-03, -3.17148156e-02,\n",
       "        -4.44056131e-02, -1.85364333e-03,  4.39616404e-02,\n",
       "        -1.96447745e-02,  1.92456115e-02,  7.26289526e-02,\n",
       "        -5.53783216e-03,  3.72339971e-02,  1.45824102e-03,\n",
       "        -2.83756945e-02, -4.79656123e-02, -4.79868315e-02,\n",
       "        -4.47778478e-02,  2.44675204e-03, -5.30624501e-02,\n",
       "        -4.07403801e-03, -1.56353749e-02, -2.35103890e-02,\n",
       "         5.47556728e-02, -6.18863367e-02, -2.28003897e-02,\n",
       "         3.72221135e-02, -7.60221779e-02,  3.55392992e-02,\n",
       "        -2.70718988e-02,  6.24295184e-03,  1.28883850e-02,\n",
       "         1.56357121e-02,  8.31977930e-03, -1.23971258e-03,\n",
       "        -2.70940829e-02,  4.87811584e-03,  2.23382544e-02,\n",
       "         1.06848618e-02, -1.70975849e-02, -2.07393356e-02,\n",
       "         1.35170261e-03,  4.22932543e-02, -2.02791169e-02]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt = \"Ronald Reagan was a\"\n",
    "\n",
    "emb_prompt = embedder.encode([test_prompt], normalize_embeddings=True)\n",
    "emb_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf2153",
   "metadata": {},
   "source": [
    "While this vector does not provide much information to us humans, we could calculate the cosine similarity of this embedding to all other sentences in our `facts` list and extract the fact that has the **most** similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "91b751b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reagan fact, Fortieth: Ronald Reagan served 1981–1989; Republican.\n",
      "Washington fact, First president: George Washington served 1789–1797; no formal party.\n"
     ]
    }
   ],
   "source": [
    "reagan_fact = facts[12]\n",
    "washington_fact = facts[0]\n",
    "\n",
    "print(\"Reagan fact,\", reagan_fact)\n",
    "print(\"Washington fact,\", washington_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "04e4ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of original prompt to Reagan fact [[0.74524]]\n",
      "Similarity of original prompt to Washington fact [[0.4231794]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# get embeddings of the two facts\n",
    "emb_reagan = embedder.encode([reagan_fact], normalize_embeddings=True)\n",
    "emb_washington = embedder.encode([washington_fact], normalize_embeddings=True)\n",
    "\n",
    "# calculate cosine similarity\n",
    "sim_reagan = dot(emb_prompt, emb_reagan.T)/(norm(emb_prompt) * norm(emb_reagan))\n",
    "sim_washington = dot(emb_prompt, emb_washington.T)/(norm(emb_prompt) * norm(emb_washington))\n",
    "\n",
    "print(\"Similarity of original prompt to Reagan fact\", sim_reagan)\n",
    "print(\"Similarity of original prompt to Washington fact\", sim_washington)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36092e2a",
   "metadata": {},
   "source": [
    "To speed up the extraction of similar strings (also known as documents), we utilize the `FAISS` library. This provides us a database (similar to a SQL database) that specializes in searching highly dimensional vector embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "842cf8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb278d98",
   "metadata": {},
   "source": [
    "Now that we've added our embeddings to our vector database, we can perform operations such as the extraction of the top 3 similar facts. Let's evaluate our test prompt and see which documents are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "274c8c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74524    0.5902182  0.56826836]]\n",
      "[[12 11 13]]\n"
     ]
    }
   ],
   "source": [
    "# use FAISS to get top 3 similar vectors\n",
    "top_k = 3\n",
    "\n",
    "scores, ids = index.search(emb_prompt, top_k)\n",
    "\n",
    "print(scores)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3c540f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top k results for prompt: Ronald Reagan was a\n",
      "\n",
      "fact Fortieth: Ronald Reagan served 1981–1989; Republican. score 0.7452399730682373 \n",
      "id 12\n",
      "\n",
      "fact Thirty-ninth: Jimmy Carter served 1977–1981; Democratic. score 0.590218186378479 \n",
      "id 11\n",
      "\n",
      "fact Forty-first: George H. W. Bush served 1989–1993; Republican. score 0.568268358707428 \n",
      "id 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Top k results for prompt:\", test_prompt)\n",
    "\n",
    "top_facts = []\n",
    "for i in range(top_k):\n",
    "    score = float(scores[0][i])\n",
    "    ident = int(ids[0][i])\n",
    "    fact = facts[int(ids[0][i])]\n",
    "    top_facts.append(fact)\n",
    "\n",
    "    print(\"\\nfact\", fact, \"score\", score, \"\\nid\", ident)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4128c64",
   "metadata": {},
   "source": [
    "We can attach these top 3 facts to our original prompt (along with some system-level instructions) to help our LLM provide a more accurate answer. First let's generate our \"context\", which provides relevant information to our original prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fae1559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fortieth: Ronald Reagan served 1981–1989; Republican.\n",
      "Thirty-ninth: Jimmy Carter served 1977–1981; Democratic.\n",
      "Forty-first: George H. W. Bush served 1989–1993; Republican.\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\n",
    "for f in top_facts:\n",
    "    context += \"\\n\" + f\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa711683",
   "metadata": {},
   "source": [
    "Next, let's generate our system-level instructions to \"point\" our model towards the context we constructed for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e249f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Use ONLY these facts to answer the question. If unknown, say 'Not in facts.'\\nFacts:\\n\\nFortieth: Ronald Reagan served 1981–1989; Republican.\\nThirty-ninth: Jimmy Carter served 1977–1981; Democratic.\\nForty-first: George H. W. Bush served 1989–1993; Republican.\\n\\nRonald Reagan was a\""
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt = (\n",
    "    \"Use ONLY these facts to answer the question. If unknown, say 'Not in facts.'\\n\"\n",
    "    f\"Facts:\\n{context}\\n\\n\"\n",
    "    f\"{test_prompt}\"\n",
    ")\n",
    "\n",
    "rag_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f2aca",
   "metadata": {},
   "source": [
    "And now we can test out how are minimal \"RAG\" operates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0ea59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use ONLY these facts to answer the question. If unknown, say 'Not in facts.'\n",
      "Facts:\n",
      "\n",
      "Fortieth: Ronald Reagan served 1981–1989; Republican.\n",
      "Thirty-ninth: Jimmy Carter served 1977–1981; Democratic.\n",
      "Forty-first: George H. W. Bush served 1989–1993; Republican.\n",
      "\n",
      "Ronald Reagan was a popular figure in the Republican Party. He was the\n"
     ]
    }
   ],
   "source": [
    "out = pipe(rag_prompt, max_new_tokens=10, do_sample=True, temperature=0.5)\n",
    "print(out[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622ef26",
   "metadata": {},
   "source": [
    "Notice that this vastly differs from what the models response would look like if we did not provide this contextual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "29af8593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ronald Reagan was a Republican presidential candidate in 1992 and was the third Republican\n"
     ]
    }
   ],
   "source": [
    "out = pipe(test_prompt, max_new_tokens=10, do_sample=True, temperature=0.5)\n",
    "print(out[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee5b5d",
   "metadata": {},
   "source": [
    "To confirm the validity of RAGs & Vector DB, let's try out this technique on our original prompt about the first US president. Except this time, let's make these techniques concrete by formalizing them into functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a331e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k(emb_prompt, k=3):\n",
    "    \"\"\"Get top 3 similar facts to original prompt embedding\n",
    "    \"\"\"\n",
    "    _, ids = index.search(emb_prompt, k)\n",
    "\n",
    "    top_facts = []\n",
    "    for i in ids[0]:\n",
    "        fact = facts[i]\n",
    "        top_facts.append(fact)\n",
    "    \n",
    "    return top_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d25b51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(facts, og_prompt):\n",
    "    \"\"\"Create a system prompt using the top 3 facts to inform answers\n",
    "    \"\"\"\n",
    "    context = \"\"\n",
    "    for f in facts:\n",
    "        context += \"\\n\" + f\n",
    "\n",
    "    prompt = (\n",
    "        \"Use ONLY these facts to answer the question. If unknown, say 'Not in facts.'\\n\"\n",
    "        f\"Facts:\\n{context}\\n\\n\"\n",
    "        f\"{og_prompt}\"\n",
    "    )\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "03eaa9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top k results for prompt: The first president of the United States was \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Second president: John Adams served 1797–1801; Federalist.',\n",
       " 'First president: George Washington served 1789–1797; no formal party.',\n",
       " 'Third president: Thomas Jefferson served 1801–1809; Democratic-Republican.']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate embedding of original prompt\n",
    "emb_prompt = embedder.encode([prompt], normalize_embeddings=True)\n",
    "\n",
    "# get top 3 facts from original prompt\n",
    "top_facts = get_top_k(emb_prompt, 3)\n",
    "\n",
    "print(\"Top k results for prompt:\", prompt)\n",
    "top_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2fcb1ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Prompt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Use ONLY these facts to answer the question. If unknown, say 'Not in facts.'\\nFacts:\\n\\nSecond president: John Adams served 1797–1801; Federalist.\\nFirst president: George Washington served 1789–1797; no formal party.\\nThird president: Thomas Jefferson served 1801–1809; Democratic-Republican.\\n\\nThe first president of the United States was \""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct prompt using newly found context\n",
    "rag_prompt = construct_prompt(top_facts, prompt)\n",
    "\n",
    "print(\"RAG Prompt\")\n",
    "rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5fbee68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use ONLY these facts to answer the question. If unknown, say 'Not in facts.'\n",
      "Facts:\n",
      "\n",
      "Second president: John Adams served 1797–1801; Federalist.\n",
      "First president: George Washington served 1789–1797; no formal party.\n",
      "Third president: Thomas Jefferson served 1801–1809; Democratic-Republican.\n",
      "\n",
      "The first president of the United States was _____________.\n",
      "Second president: John Adams served\n"
     ]
    }
   ],
   "source": [
    "out = pipe(rag_prompt, max_new_tokens=10, do_sample=True, temperature=0.5)\n",
    "print(out[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0b678",
   "metadata": {},
   "source": [
    "## Vector Databases & RAGS in OpenAI\n",
    "\n",
    "As we can see from the above example however, it's going to take a lot more work to get `distilgpt2` to a capacity where it is able to assist in everyday business automation. Therefore, for the remainder of this exercise we will utilize the `openai` API. \n",
    "\n",
    "Particularly, we will explore how we could pass `pdfs` to the openai API. In this example, we will pass a pdf of \"presidential facts.\"\n",
    "\n",
    "Therefore, we will instead utilize the `openai` API to interact with a vector store. This will then be used to inform `gpt-4o-mini`'s answers. While a vector store is not as comprehensive as a [vector database](https://myscale.com/blog/vector-store-vs-vector-database-comparison-guide/), this tool still allows us to efficiently search the semantic space to augment our responses.\n",
    "\n",
    "Particularly we will interact with the vector store with the `id` \"proj_fHRnVJY0Oyfm1ufG1sffxa6W.\"\n",
    "\n",
    "To begin running the code below, copy & paste the provided API key in the code-block below.\n",
    "\n",
    "**DO NOT PUSH THIS KEY TO GITHUB**  \n",
    "**DO NOT PUSH THIS KEY TO GITHUB**  \n",
    "**DO NOT PUSH THIS KEY TO GITHUB**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f89f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# access the specific OpenAI project\n",
    "client = OpenAI(project=\"proj_fHRnVJY0Oyfm1ufG1sffxa6W\")\n",
    "# specify vector store id\n",
    "vec_id = \"vs_689a38d0704081919c7e463d0efd9dfb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90593e20",
   "metadata": {},
   "source": [
    "Here we initialize our `openai` client and specify which vector store we will use.\n",
    "\n",
    "We opent this file the same way we would for basic `I/O` operations. We can then create this file in our remote vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the pdf file and create an object which could be interpreted by openai\n",
    "with open(\"pres_facts.pdf\", \"rb\") as file_obj:\n",
    "    f = client.files.create(file=file_obj, purpose=\"assistants\")\n",
    "\n",
    "    # push pdf to vector store\n",
    "    client.vector_stores.files.create(\n",
    "        vector_store_id=vec_id,\n",
    "        file_id=f.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5aece",
   "metadata": {},
   "source": [
    "Now that we have our file within our vector store, we can utilize it to augment our responses. Note that the only thing we need to specify are our model \"tools.\" This allows our model to search a specific vector store for more information.\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": (vector store id that contains our file info)\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c74a0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Madison weighed less than 100 pounds.\n"
     ]
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model='gpt-4-turbo',\n",
    "    input='How much did James Madison weigh?',\n",
    "    tools=[{\"type\": \"file_search\", \"vector_store_ids\": [vec_id]}],\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a47ea",
   "metadata": {},
   "source": [
    "Again, let's see how our model works without the addition of our vector files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1c8c793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no specific record of James Madison's exact weight throughout his life. However, he was known for his small stature. Historical sources often describe him as standing around 5 feet 4 inches tall and being quite slight in build, leading to estimates that his weight was under 100 pounds during his presidency. Madison's light frame and shorter height were distinctive characteristics noted by his contemporaries.\n"
     ]
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model='gpt-4-turbo',\n",
    "    input='How much did James Madison weigh?'\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf3f8b",
   "metadata": {},
   "source": [
    "Now that we know how to augment our responses, let's try out the `rag_case_study.ipynb` exercise!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
