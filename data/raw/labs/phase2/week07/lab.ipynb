{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Unsupervised Learning\n",
    "\n",
    "In this section we introduce unsupervised learning—a process where data is explored without predefined labels. Unsupervised learning is applied in customer segmentation, content recommendation, and many other fields. The examples in this lab follow the lab plan outlined in the attached lab plan document fileciteturn0file0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print('Welcome to the Unsupervised Learning Lab!')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above prints a welcome message to introduce the lab. \n",
    "\n",
    "Challenge: Modify the printed message to include additional details about unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the K-Means Clustering Algorithm\n",
    "\n",
    "K-Means clustering partitions data into groups by iteratively assigning data points to the closest centroid and recalculating centroids using squared Euclidean distance. This section uses a simple toy dataset to illustrate these concepts, as described in the lab plan fileciteturn0file0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a toy dataset of 2D points\n",
    "X = np.array([[1, 2], [1, 4], [2, 3], [5, 8], [6, 9], [5, 6]])\n",
    "\n",
    "# Set the number of clusters\n",
    "k = 2\n",
    "\n",
    "# Randomly assign a cluster for each data point\n",
    "np.random.seed(42)  # for reproducibility\n",
    "assignments = np.random.randint(0, k, size=X.shape[0])\n",
    "print('Initial cluster assignments:', assignments)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines a small toy dataset and randomly assigns each point to one of two clusters. The use of a fixed random seed ensures consistent results upon each run. \n",
    "\n",
    "Challenge: Experiment with a different random seed or change the number of clusters to observe how the initial assignments vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def squared_distance(a, b):\n",
    "    \"\"\"Compute the squared Euclidean distance between two vectors.\"\"\"\n",
    "    return np.sum((a - b) ** 2)\n",
    "\n",
    "# Calculate the squared distance between the first two points\n",
    "dist = squared_distance(X[0], X[1])\n",
    "print('Squared distance between first two points:', dist)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above computes the squared Euclidean distance between two vectors. In the example, it calculates the distance between the first two points of the toy dataset. \n",
    "\n",
    "Challenge: Enhance the function by adding a print statement that shows the individual differences between vector elements during the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute centroids based on initial cluster assignments\n",
    "centroids = []\n",
    "for i in range(k):\n",
    "    cluster_points = X[assignments == i]\n",
    "    centroids.append(np.mean(cluster_points, axis=0))\n",
    "centroids = np.array(centroids)\n",
    "print('Computed centroids:', centroids)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code calculates centroids by computing the mean of the data points assigned to each cluster. The resulting centroids are then printed. \n",
    "\n",
    "Challenge: Modify the centroid computation to use the median of the points instead of the mean, and compare the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the toy dataset with the initial cluster assignments\n",
    "plt.scatter(X[:, 0], X[:, 1], c=assignments, cmap='viridis', label='Data Points')\n",
    "\n",
    "# Plot the computed centroids\n",
    "for i, center in enumerate(centroids):\n",
    "    plt.scatter(center[0], center[1], marker='x', color='red', s=100, label=f'Centroid {i}')\n",
    "\n",
    "plt.title('Toy Dataset Cluster Visualization')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization displays the toy dataset colored by their respective initial cluster assignments, with red 'x' markers indicating the centroids. \n",
    "\n",
    "Challenge: Modify the visualization by changing the colormap or marker style, and discuss the effect on your interpretation of the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code-Along Activity: Building K-Means from Scratch\n",
    "\n",
    "In this section, we build the K-Means algorithm step by step. We begin by defining helper functions to compute cluster assignments and update centroids, and then combine these into the main K-Means function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compute_clusters(X, centroids):\n",
    "    import numpy as np\n",
    "    clusters = []\n",
    "    for x in X:\n",
    "        distances = [np.sum((x - c) ** 2) for c in centroids]\n",
    "        clusters.append(np.argmin(distances))\n",
    "    return np.array(clusters)\n",
    "\n",
    "# Example usage:\n",
    "# clusters = compute_clusters(X, centroids)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function compute_clusters assigns each data point in X to the closest centroid using squared Euclidean distance. \n",
    "\n",
    "Challenge: Modify this function to use an alternative distance metric, such as Manhattan distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def update_centroids(X, clusters, k):\n",
    "    import numpy as np\n",
    "    new_centroids = []\n",
    "    for i in range(k):\n",
    "        points = X[clusters == i]\n",
    "        new_centroids.append(np.mean(points, axis=0))\n",
    "    return np.array(new_centroids)\n",
    "\n",
    "# Example usage:\n",
    "# new_centroids = update_centroids(X, assignments, k)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update_centroids function recalculates the centroids by finding the mean of data points in each cluster. \n",
    "\n",
    "Challenge: Adjust the function to handle empty clusters (for example, by keeping the previous centroid if no points are assigned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def k_means(X, k, max_iter=10):\n",
    "    import numpy as np\n",
    "    # Initialize centroids by selecting k random data points\n",
    "    indices = np.random.choice(len(X), k, replace=False)\n",
    "    centroids = X[indices]\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        clusters = compute_clusters(X, centroids)\n",
    "        new_centroids = update_centroids(X, clusters, k)\n",
    "        \n",
    "        # Check for convergence using allclose for numerical stability\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return centroids, clusters\n",
    "\n",
    "# Run K-Means on the toy dataset with a higher iteration limit\n",
    "centroids_final, clusters_final = k_means(X, k, max_iter=20)\n",
    "print('Final centroids:', centroids_final)\n",
    "print('Final cluster assignments:', clusters_final)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k_means function integrates the helper functions to perform clustering. It initializes centroids, iterates to update cluster assignments and centroids, and stops when the centroids converge. \n",
    "\n",
    "Challenge: Re-run the k_means function with a different value of k (for example, k=3) and observe how the final centroids and assignments differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a Real-World Inspired Dataset\n",
    "\n",
    "In this section we apply our K-Means algorithm to a real-world dataset. The Iris dataset is used with its first two features to facilitate 2D visualization. This practical example mirrors real-world clustering challenges described in the lab plan fileciteturn0file0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "# Extract the first two features (sepal length and sepal width)\n",
    "X_real = data.data[:, :2]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code loads the Iris dataset and selects its first two features to simplify the clustering visualization. \n",
    "\n",
    "Challenge: Try selecting a different pair of features (for example, the last two features) and analyze how the resulting clusters change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "centroids_real, clusters_real = k_means(X_real, 3, max_iter=20)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_real[:, 0], X_real[:, 1], c=clusters_real, cmap='viridis', label='Data Points')\n",
    "plt.scatter(centroids_real[:, 0], centroids_real[:, 1], marker='x', color='red', s=100, label='Centroids')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('K-Means Clustering on Iris Dataset (first 2 features)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization displays the Iris dataset with k=3 clusters. Data points are colored by cluster assignment and centroids are marked in red. \n",
    "\n",
    "Challenge: Experiment with different values of k and describe how the cluster visualization changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions: Filtering Techniques and Practical Applications\n",
    "\n",
    "Clustering results enable filtering data for applications like collaborative and content-based filtering. In this section, we filter the Iris dataset based on a specific cluster assignment to simulate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter the Iris dataset for data points assigned to cluster 0\n",
    "filtered_data = X_real[clusters_real == 0]\n",
    "print('Data points in Cluster 0:')\n",
    "print(filtered_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code filters the dataset to display only those data points that belong to cluster 0. This approach can be extended to various filtering techniques in real-world applications. \n",
    "\n",
    "Challenge: Modify the filtering criterion to display data points from a different cluster and analyze the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection and Professional Relevance\n",
    "\n",
    "Reflect on the clustering process and its practical implications. Consider the effects of random initialization, choice of k, and feature scaling on the clustering results, as well as how these aspects relate to real-world data science challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def print_reflections():\n",
    "    questions = [\n",
    "        'How does random initialization affect the final clusters?',\n",
    "        'What changes do you observe when you modify the number of clusters (k)?',\n",
    "        'How might feature scaling impact the clustering outcome?'\n",
    "    ]\n",
    "    for q in questions:\n",
    "        print(q)\n",
    "\n",
    "print_reflections()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above prints a set of reflective questions to help you consider the sensitive aspects of the K-Means algorithm, such as initialization and convergence criteria. \n",
    "\n",
    "Challenge: Extend the list with an additional question regarding the impact of convergence tolerance on algorithm performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}