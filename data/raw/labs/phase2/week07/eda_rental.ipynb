{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce7d689",
   "metadata": {},
   "source": [
    "# Apartment Price Prediction Case Study\n",
    "\n",
    "You are a data scientist at Willoz, a real-estate online marketplace based in Albuquerque, NM. \n",
    "\n",
    "Your team has been contracted by a property aggregator to improve user engagement by offering a personalized recommendation widget. This feature will allow users to enter their apartment preferences (size, pet-policy) and receive a prediction of a typical apartment price. You've been provided with a historical dataset of 10,000 rental listings scraped from various sources containing predictors such as bedrooms, price, location, and descriptions.\n",
    "\n",
    "We will demo\n",
    "\n",
    "Your task is to:\n",
    "* Explore and clean the dataset,\n",
    "* Engineer new features using the insights you've discovered from your EDA,\n",
    "* Deploy it locally using a light-weight streamlit app that takes in apartment features and returns a price.\n",
    "\n",
    "Let's use the patterns we've learned about in class to complete this case study together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02dea4",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "Let's get started with exploratory data analysis. \n",
    "\n",
    "* Load the dataset and identify the structure and content of each column. \n",
    "* Identify analytical & predictive questions to determine valuable analyses. \n",
    "* Generate summary statistics and visualizations on features such as price, bedrooms, bathrooms, square_feet, and cityname.  \n",
    "* Investigate missing or inconsistent values and decide how to address them.  \n",
    "* Identify correlations or relationships that might impact housing price or desirability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93933b6f",
   "metadata": {},
   "source": [
    "### Identifying the Structure of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals = pd.read_csv(\"apartments_for_rent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the shape\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the columns\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the first few rows\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d23a6c",
   "metadata": {},
   "source": [
    "## Forming Good Exploratory Questions\n",
    "\n",
    "Let's consider good exploratory questions given the structure of our dataset and the types of variables our dataset contains. Consider these questions and how we can apply them to our dataset to ask specific questions about our columns.\n",
    "\n",
    "* Which column are we attempting to predict?\n",
    "* What numerical variables do we have? Which visualization techniques can we apply to these variables?\n",
    "* What categorical variables do we have? Which visualization techniques can we apply to these variables?\n",
    "* How can we explore the relationships between numeric vs numeric? What about categorical vs numeric? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32bd5d",
   "metadata": {},
   "source": [
    "### Generate Visualizations\n",
    "\n",
    "Let's perform both univariate and bivariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc06cd21",
   "metadata": {},
   "source": [
    "### Investigate Missing, Incosistent, or Outlier Values. Identify the \"Shape\" of your Data (Univariate Analysis)\n",
    "\n",
    "Let's identify the distributions of our numeric columns, as well as our categorical columns. Additionally, let's observe if we have any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0726c",
   "metadata": {},
   "source": [
    "### Identify correlations or relationships (Bivariate Analysis)\n",
    "\n",
    "Now, let's observe if we have any clear relationships between our predictors & our target (price). Remember, our predictors could be categorical as well! Furthermore, even if our predictors are expressed as numerical, they can still *manifest* themselves as discrete if we don't expect decimal values, and we are limited to a range of numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ada23",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7236ad6",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Looking at our distributions and null values, it appears that we do have outlier values as well as missing data. Furthermore, it appears that there are specific columns which **should not** be included in our prediction step as it could potentially bias our data to specific samples. This includes columns like `id`, `category`, `title`, `body`, `address`, `latitude`, `longitude`, `source`, `time`, and others.\n",
    "\n",
    "Remember, we want to be able to predict the price of a rental property given the independent features of an apartment that we have at the ready. Features such as `id`, `title` and `body` are already expressed in our sample through other columns such as `bathrooms` and `bedrooms`. \n",
    "\n",
    "For our predictive columns, must make an executive decision as to what we want to do with missing values. We could either:\n",
    "* Drop columns with missing values,\n",
    "* Drop rows with missing values (and remove roughly half of our dataset),\n",
    "* Impute missing values,\n",
    "* Or perform all 3 steps in some specific order. The order in which you apply these steps result in different datasets!\n",
    "\n",
    "Take a close look at your dataset however! A \"None\" might not always mean `NA` in this dataset. For example, what might \"None\" mean in the context of the `pets_allowed` or `amenities` columns?\n",
    "\n",
    "We should also decide what to do with outlier values. We could either:\n",
    "* Transform columns to fit a normal distribution\n",
    "* Filter your dataset to not include atypical values in your analysis.\n",
    "\n",
    "More information on possible data transformations are listed here: https://developers.google.com/machine-learning/crash-course/numerical-data/normalization.\n",
    "\n",
    "Furthermore it looks like we have data that could be transformed to ensure we have as much as data as available for greater predictive capabilities. This includes:\n",
    "* Encoding specific categorical predictors in our analysis,\n",
    "* Converting values with alternative units of measurement into 1 standard\n",
    "\n",
    "Which data transformation technique have we learned about before which can assist us in this?\n",
    "\n",
    "Remember, there is no one concrete methodology. You must be able to choose transformation techiques and justify them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
