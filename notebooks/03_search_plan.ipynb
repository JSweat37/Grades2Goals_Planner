{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af13f703",
   "metadata": {},
   "source": [
    "# Search & Study Plan Generation\n",
    "\n",
    "The **goal of this notebook** is to connect our semantic search (using FAISS) with a language model (LLM) to generate a personalized **7 day study plan** from student feedback.  \n",
    "\n",
    "### What this notebook does\n",
    "1. Loads pre-processed slide and lab chunks (from `data/processed/`).  \n",
    "2. Loads FAISS indexes so we can quickly search the most relevant content.  \n",
    "3. Searches the slides and labs for matches to a student’s feedback.  \n",
    "4. Builds a formatted context block that attaches simple **[CITATION] markers** to each chunk.  \n",
    "5. Sends the feedback + context to an LLM to compose a **7 day plan** with review, practice, and reflection tasks.  \n",
    "6. Prints the plan in the notebook and saves it for later use.  \n",
    "\n",
    "### Inputs\n",
    "- `slides_chunks.parquet` — processed lecture slides  \n",
    "- `labs_chunks.parquet` — processed Jupyter notebooks  \n",
    "- `faiss_slides.index` — FAISS index for slides  \n",
    "- `faiss_labs.index` — FAISS index for labs  \n",
    "\n",
    "### Outputs\n",
    "- Printed 7 day study plan in the notebook  \n",
    "- Option to export/save as JSON or CSV for later analysis  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84587bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# Add project root to Python path\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# From utils.py pull helper functions \n",
    "from src.utils import( \n",
    "    load_chunks,\n",
    "    load_index,\n",
    "    search_labs,\n",
    "    search_slides,\n",
    "    FAISS_SLIDES_PATH,\n",
    "    FAISS_LABS_PATH\n",
    ")\n",
    "\n",
    "load_dotenv(override=True)  # take environment variables from .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "583ea6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slides rows: 40 |FAISS size: 40\n",
      "Labs rows:   1410 |FAISS size: 1410\n"
     ]
    }
   ],
   "source": [
    "# Load Data and FIASS\n",
    "slides_df, labs_df = load_chunks()\n",
    "\n",
    "slides_index = load_index(FAISS_SLIDES_PATH)\n",
    "labs_index = load_index(FAISS_LABS_PATH)\n",
    "\n",
    "print(\"Slides rows:\", len(slides_df), \"|FAISS size:\", slides_index.ntotal)\n",
    "print(\"Labs rows:  \", len(labs_df), \"|FAISS size:\", labs_index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8851ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context(lab_matches, slide_matches):\n",
    "    \"\"\"\n",
    "    Combine lab and slide search results into a single text block \n",
    "    that we can pass to the language model.\n",
    "    \n",
    "    Args:\n",
    "        lab_matches (pd.DataFrame): results from search_labs()\n",
    "        slide_matches (pd.DataFrame): results from search_slides()\n",
    "    \n",
    "    Returns:\n",
    "        str: formatted context with numbered [CITATION] markers\n",
    "    \"\"\"\n",
    "\n",
    "    # List to hold formatted text chunks\n",
    "    context_texts = []\n",
    "\n",
    "    # Start citation numbers at 1\n",
    "    ref_number = 1       \n",
    "\n",
    "    # --- Add lab matches first ---\n",
    "    for _, row in lab_matches.iterrows():\n",
    "        # Build one formatted line for this lab result\n",
    "        line = f\"[{ref_number}] (Lab file: {row['file']}) {row['text']}\"\n",
    "        context_texts.append(line)  # store the line\n",
    "        ref_number += 1             # move to the next citation number\n",
    "\n",
    "    # --- Add slide matches next ---\n",
    "    for _, row in slide_matches.iterrows():\n",
    "        # Build one formatted line for this slide result\n",
    "        line = f\"[{ref_number}] (Slide file: {row['file']} | Page {row['page']}) {row['text']}\"\n",
    "        context_texts.append(line)  # store the line\n",
    "        ref_number += 1             # move to the next citation number\n",
    "\n",
    "    # Join everything into one string with blank lines between\n",
    "    return \"\\n\\n\".join(context_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5739f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] (Lab file: sql_refresher.ipynb) ### SQL JOINs (Review)\n",
      "JOINs are used to combine data from two or more tables based on a related column.\n",
      "- `INNER JOIN`: returns only matching rows\n",
      "- `LEFT JOIN`: returns all rows from the left table, even if there are no matches in the right table\n",
      "Try both join types below!\n",
      "\n",
      "[2] (Lab file: sql_refresher.ipynb) #### SQL JOINs\n",
      "JOINs combine rows from two or more tables based on a related column. Try changing the join type or columns.\n",
      "\n",
      "[3] (Lab file: w9-class2.ipynb) ### Joins\n",
      "\n",
      "inner joins:\n",
      "```sql\n",
      "SELECT *\n",
      "FROM orders\n",
      "INNER JOIN users ON orders.user_id = users.id;\n",
      "```\n",
      "\n",
      "left joins:\n",
      "```sql\n",
      "SELECT *\n",
      "FROM users\n",
      "LEFT JOIN orders ON users.id = orders.user_id;\n",
      "```\n",
      "right joins:\n",
      "```sql\n",
      "SELECT *\n",
      "FROM users\n",
      "RIGHT JOIN orders ON users.id = orders.user_id;\n",
      "```\n",
      "full out\n"
     ]
    }
   ],
   "source": [
    "# Example student feedback ( swap this for any test case)\n",
    "feedback_text = \"I lost points on SQL joins and I keep mixing up inner vs left vs right joins.\"\n",
    "lab_matches = search_labs(labs_index, labs_df, feedback_text, top_k=5)\n",
    "slide_matches = search_slides(slides_index, slides_df, feedback_text, top_k=4)\n",
    "\n",
    "context = make_context(lab_matches, slide_matches)\n",
    "print(context[:800])  # show a preview of the context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10c29779",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)  # take environment variables from .env file\n",
    "\n",
    "# Create a single OpenAI client (reads key from environment)\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def generate_7_day_plan(feedback_text, slides_index, slides_df, labs_index, labs_df, top_k_slides=5, top_k_labs=5, model_name=\"gpt-4o-mini\"): \n",
    "    \"\"\"\n",
    "    How it works:\n",
    "    1) Search slides and labs separately.\n",
    "    2) Concatenate the results (labs first by default since they are practical).\n",
    "    3) Build a single context block with simple citations.\n",
    "    4) Call OpenAI to write a 7-day plan with spaced review.\n",
    "    5) Return the generated text.\n",
    "\n",
    "    Args:\n",
    "        feedback_text (str): Student's feedback, \"I lost points on SQL joins and confusion matrix.\"\n",
    "        top_k_slides (int): Number of slide chunks to include.\n",
    "        top_k_labs   (int): Number of lab chunks to include.\n",
    "        model_name   (str): OpenAI chat model.\n",
    "\n",
    "    Returns:\n",
    "        str: The study plan text generated by the LLM.\n",
    "    \"\"\"\n",
    "    # Search slides and labs\n",
    "    slides_results = search_slides(slides_index, slides_df, feedback_text, top_k=top_k_slides)\n",
    "    labs_results   = search_labs(labs_index, labs_df, feedback_text, top_k=top_k_labs)\n",
    "\n",
    "    # Make context\n",
    "    context = make_context(labs_results, slides_results)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an academic coach for a data science course. \"\n",
    "        \"You must create a concrete 7-day micro-task plan using ONLY the provided context. \"\n",
    "        \"Ensure tasks alternate between review (reading/notes), application (coding exercises), and reflection.\"\n",
    "        \"Each day should include 2–4 actionable tasks, with estimated time, and a citation line that points back to the source. \"\n",
    "        \"Use spaced review on Day 1, Day 3, and Day 6. \"\n",
    "        \"If context is insufficient for any part, state that clearly.\"\n",
    "    )\n",
    "    \n",
    "    user_prompt = (\n",
    "        f\"Student feedback: {feedback_text}\\n\\n\"\n",
    "        f\"Context from course materials (slides and labs):\\n\"\n",
    "        f\"{context}\\n\"\n",
    "        \"Now write the 7-day plan in this structure:\\n\"\n",
    "        \"Day 1 — Understand\\n\"\n",
    "        \"- Task 1 (est. 15–25 min) — description [CITATION]\\n\"\n",
    "        \"- Task 2 (est. 10–20 min) — description [CITATION]\\n\"\n",
    "        \"Day 2 — Apply\\n\"\n",
    "        \"- Task 1 ...\\n\"\n",
    "        \"...\\n\"\n",
    "        \"Day 7 — Checkpoint\\n\"\n",
    "        \"- Mini-quiz or small coding task ...\\n\"\n",
    "        \"\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"- Use only facts available in the context above.\\n\"\n",
    "        \"- Each task line should end with a [CITATION] using the [SOURCE: ...] entry from context.\\n\"\n",
    "        \"- If something is unclear or missing, say so.\\n\"\n",
    "    )\n",
    "\n",
    "    # Call OpenAI chat completion\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,  # low temperature for focused output\n",
    "        max_tokens=1000   # adjust as needed\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f343b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 7-Day Micro-Task Plan for SQL Joins\n",
      "\n",
      "#### Day 1 — Understand\n",
      "- **Task 1 (est. 15–25 min)** — Review the definitions and differences between `INNER JOIN`, `LEFT JOIN`, and `RIGHT JOIN`. Take notes on when to use each type. [CITATION: 1]\n",
      "- **Task 2 (est. 10–20 min)** — Read through the SQL JOIN examples provided in the course materials and write down the SQL syntax for each type of join. [CITATION: 3]\n",
      "\n",
      "#### Day 2 — Apply\n",
      "- **Task 1 (est. 20–30 min)** — Use the interactive SQL playground to practice writing `INNER JOIN` queries. Experiment with different tables and columns. [CITATION: 6]\n",
      "- **Task 2 (est. 15–25 min)** — Complete a coding exercise that requires you to write `LEFT JOIN` queries based on provided datasets. [CITATION: 1]\n",
      "\n",
      "#### Day 3 — Review\n",
      "- **Task 1 (est. 15–25 min)** — Revisit your notes from Day 1 and summarize the key points about SQL JOINs. Focus on the differences between join types. [CITATION: 1]\n",
      "- **Task 2 (est. 10–20 min)** — Go through the SQL JOIN examples again and try to explain them in your own words. [CITATION: 3]\n",
      "\n",
      "#### Day 4 — Apply\n",
      "- **Task 1 (est. 20–30 min)** — Write SQL queries using `RIGHT JOIN` and `FULL OUTER JOIN` in the interactive SQL playground. Test different scenarios. [CITATION: 3]\n",
      "- **Task 2 (est. 15–25 min)** — Solve SQL Leetcode questions that focus on JOIN operations. [CITATION: 7]\n",
      "\n",
      "#### Day 5 — Reflect\n",
      "- **Task 1 (est. 15–25 min)** — Reflect on the challenges faced while writing JOIN queries. Write down any specific areas where you feel less confident. [CITATION: 1]\n",
      "- **Task 2 (est. 10–20 min)** — Discuss your reflections with a peer or mentor, focusing on the differences between the join types. [CITATION: 1]\n",
      "\n",
      "#### Day 6 — Review\n",
      "- **Task 1 (est. 15–25 min)** — Go over your notes and reflections from Days 1 and 5. Create a comparison chart for `INNER JOIN`, `LEFT JOIN`, and `RIGHT JOIN`. [CITATION: 1]\n",
      "- **Task 2 (est. 10–20 min)** — Revisit the SQL JOIN examples and practice writing queries for each type again, ensuring you understand their outputs. [CITATION: 3]\n",
      "\n",
      "#### Day 7 — Checkpoint\n",
      "- **Task 1 (est. 30 min)** — Complete a mini-quiz or small coding task that requires you to write queries using all types of joins. Assess your understanding based on the results. [CITATION: 1]\n",
      "- **Task 2 (est. 15 min)** — Review the quiz results and identify any areas that still need improvement. Plan next steps for further practice. [CITATION: 1]\n",
      "\n",
      "This structured plan will help reinforce your understanding of SQL JOINs and improve your coding skills in this area.\n",
      "Saved (raw text) plan to: ../data/processed/example_plan.json\n"
     ]
    }
   ],
   "source": [
    "feedback_text = \"I lost points on SQL joins and I keep mixing up inner vs left vs right joins.\"\n",
    "plan_text = generate_7_day_plan(feedback_text, slides_index, slides_df, labs_index, labs_df, top_k_slides=4, top_k_labs=6, model_name=\"gpt-4o-mini\")\n",
    "print(plan_text)\n",
    "\n",
    "out_path = Path(\"../data/processed/example_plan.json\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save as a JSON object with a single string field\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"plan_text\": plan_text}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved (raw text) plan to:\", out_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff36218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Topic \n",
    "#Topic_keywords = {\n",
    "#    \"sql\": [\"join\", \"left join \", \"right join\", \"inner join\", \"outer join\", \"select\", \"from\", \"where\", \"group by\", \"order by\", \"having\", \"union\", \"intersect\", \"except\", \"subquery\", \"cte\", \"window function\"],\n",
    "#    \"loops\": [\"for loop\", \"while loop\", \"do while loop\", \"nested loop\", \"break\", \"continue\", \"infinite loop\", \"loop control\"]\n",
    "\n",
    "#    def detect_topic(query):\n",
    "#        result = []\n",
    "#         for topic, keywords in Topic_keywords.items():\n",
    "#            for keyword in keywords:\n",
    "#                if keyword in query.lower():\n",
    "#                    result.append(topic)\n",
    "#        return result       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
