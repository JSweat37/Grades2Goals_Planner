{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78da3c09",
   "metadata": {},
   "source": [
    "The goal of this notebook build faiss indexes for semantic search \n",
    "- retrieve chunked data\n",
    "- built FAISS\n",
    "- Veriefed that they can be query and get results \n",
    "\n",
    "**Inputs**\n",
    "- `../data/processed/slides_chunks.parquet`  \n",
    "- `../data/processed/labs_chunks.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412fd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482f2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slides chunks exist?  True C:\\Users\\julmo\\OneDrive - University of Rochester\\TKH Labs\\Grades2Goals_Planner\\data\\processed\\slides_chunks.parquet\n",
      "Labs chunks exist?    True C:\\Users\\julmo\\OneDrive - University of Rochester\\TKH Labs\\Grades2Goals_Planner\\data\\processed\\labs_chunks.parquet\n"
     ]
    }
   ],
   "source": [
    "# Folders\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "RAW_FOLDER = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_FOLDER = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Input files \n",
    "SLIDES_CHUNKS_PATH = PROCESSED_FOLDER / \"slides_chunks.parquet\"\n",
    "LABS_CHUNKS_PATH   = PROCESSED_FOLDER / \"labs_chunks.parquet\"\n",
    "\n",
    "# Define FAISS index path\n",
    "FAISS_INDEX_PATH = PROCESSED_FOLDER / \"faiss_slides.index\"\n",
    "FAISS_LABS_INDEX_PATH = PROCESSED_FOLDER / \"faiss_labs.index\"\n",
    "\n",
    "print(\"Slides chunks exist? \", SLIDES_CHUNKS_PATH.exists(), SLIDES_CHUNKS_PATH)\n",
    "print(\"Labs chunks exist?   \", LABS_CHUNKS_PATH.exists(), LABS_CHUNKS_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b2acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slides rows: 40\n",
      "Labs rows:   1410\n"
     ]
    }
   ],
   "source": [
    "# Load chunks \n",
    "slides_df = pd.read_parquet(\"../data/processed/slides_chunks.parquet\")\n",
    "labs_df   = pd.read_parquet(\"../data/processed/labs_chunks.parquet\")\n",
    "\n",
    "# Drop empty rows\n",
    "slides_df = slides_df.dropna(subset=['text']).reset_index(drop=True)\n",
    "labs_df   = labs_df.dropna(subset=['text']).reset_index(drop=True)\n",
    "\n",
    "print(\"Slides rows:\", len(slides_df))\n",
    "print(\"Labs rows:  \", len(labs_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f9f5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Embedding model\n",
    "embedder = SentenceTransformer(\"bert-base-nli-mean-tokens\")\n",
    "\n",
    "\n",
    "def encode_normalized(texts):\n",
    "    \"\"\"Convert a single query string (what the student types) into a normalized float32 vector.\n",
    "    - normalize_embeddings=True ensures vectors have length 1, so FAISS inner product ≈ cosine similarity.\n",
    "    - We return a NumPy array with dtype float32 because FAISS expects float32 vectors.\"\"\"\n",
    "    embeddings = embedder.encode(texts, normalize_embeddings=True, show_progress_bar=True)\n",
    "    return np.asarray(embeddings, dtype=\"float32\")\n",
    "\n",
    "print(\"Embedding model loaded:\", embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3631901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c690c9d66a445afa5f18ab959f938df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8efdc2a213a4bc088ce005f50e4c442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 2 FAISS indices, one for slides and one for labs\n",
    "\n",
    "# Slides index\n",
    "slides_embeddings = encode_normalized(slides_df['text'].tolist())\n",
    "slides_index = faiss.IndexFlatIP(slides_embeddings.shape[1])\n",
    "slides_index.add(slides_embeddings)\n",
    "faiss.write_index(slides_index, FAISS_INDEX_PATH.as_posix())\n",
    "\n",
    "# Labs index\n",
    "labs_embeddings = encode_normalized(labs_df['text'].tolist())\n",
    "labs_index = faiss.IndexFlatIP(labs_embeddings.shape[1])\n",
    "labs_index.add(labs_embeddings)\n",
    "faiss.write_index(labs_index, FAISS_LABS_INDEX_PATH.as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e7b5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_slides(query_text,top_k =5):\n",
    "    \"\"\"\n",
    "    Search ONLY the slides index and return a small, readable DataFrame of results.\n",
    "\n",
    "    Steps:\n",
    "    1) Encode the query using the same embedding model and normalization.\n",
    "    2) Ask FAISS for the top_k most similar vectors from the slides index.\n",
    "    3) For each match, look up the original row in slides_df to get metadata (file, page, text).\n",
    "    4) Build a small results table with source_type, file, page, text, and the similarity score.\n",
    "    5) Sort by score descending (higher ≈ more similar).\n",
    "    \"\"\"\n",
    "    # Embed query \n",
    "    query_vector = encode_normalized([query_text])\n",
    "\n",
    "    # FAISS search\n",
    "    distances, indices = slides_index.search(query_vector, top_k)\n",
    "\n",
    "    # Turn indicies into a list of rows from slides_df\n",
    "    rows = []\n",
    "    for score, idx in zip(distances[0], indices[0]):\n",
    "        if idx < 0:  # FAISS returns -1 for empty results\n",
    "            continue\n",
    "        row = slides_df.iloc[idx] # get the mathching slide chunks\n",
    "        # result structure\n",
    "        rows.append({\n",
    "            \"source_type\": \"slide\",\n",
    "            \"file\": row['file'], # slide filename\n",
    "            \"page\": row['page'], # slide page number\n",
    "            \"text\": row['text'], # slide text chunk that matched\n",
    "            \"score\": score # similarity score  (higher the better)\n",
    "    \n",
    "        })\n",
    "\n",
    "    # Create a DataFrame and sort by score descending\n",
    "    results_df = pd.DataFrame(rows).sort_values(by=\"score\", ascending=False).reset_index(drop=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c035ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_labs(query_text,top_k =5):\n",
    "    \"\"\"\n",
    "    Search ONLY the labs index and return a small, readable DataFrame of results.\n",
    "\n",
    "    Steps:\n",
    "    1) Encode the query using the same embedding model and normalization.\n",
    "    2) Ask FAISS for the top_k most similar vectors from the labs index.\n",
    "    3) For each match, look up the original row in labs_df to get metadata (file, page, text).\n",
    "    4) Build a small results table with source_type, file, page, text, and the similarity score.\n",
    "    5) Sort by score descending (higher ≈ more similar).\n",
    "    \"\"\"\n",
    "    # Embed query \n",
    "    query_vector = encode_normalized([query_text])\n",
    "\n",
    "    # FAISS search\n",
    "    distances, indices = labs_index.search(query_vector, top_k)\n",
    "\n",
    "    # Turn indicies into a list of rows from labs_df\n",
    "    rows = []\n",
    "    for score, idx in zip(distances[0], indices[0]):\n",
    "        if idx < 0:  # FAISS returns -1 for empty results\n",
    "            continue\n",
    "        row = labs_df.iloc[idx] # get the mathching slide chunks\n",
    "        # result structure\n",
    "        rows.append({\n",
    "            \"source_type\": \"lab\",\n",
    "            \"file\": row['file'], # lab filename\n",
    "            \"text\": row['text'], # lab text chunk that matched\n",
    "            \"score\": score # similarity score  (higher the better)\n",
    "    \n",
    "        })\n",
    "\n",
    "    # Create a DataFrame and sort by score descending\n",
    "    results_df = pd.DataFrame(rows).sort_values(by=\"score\", ascending=False).reset_index(drop=True)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9092cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0067023ab50540c6afc0f5ac68f2f1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_type</th>\n",
       "      <th>file</th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slide</td>\n",
       "      <td>Introduction to Structured Databases I (1).pdf</td>\n",
       "      <td>62</td>\n",
       "      <td>Tuesday\\nOn Tuesday we will review…\\n●\\nWhat i...</td>\n",
       "      <td>0.549009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slide</td>\n",
       "      <td>Advanced SQL I.pdf</td>\n",
       "      <td>43</td>\n",
       "      <td>Tuesday\\nSQL + Python\\n●\\nHow do we design a d...</td>\n",
       "      <td>0.531278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slide</td>\n",
       "      <td>Introduction to Structured Databases II.pdf</td>\n",
       "      <td>42</td>\n",
       "      <td>Wednesday\\nMore SQL Practice!\\n●\\nSQL Leetcode...</td>\n",
       "      <td>0.493887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slide</td>\n",
       "      <td>Types of Visualizations Review.pdf</td>\n",
       "      <td>64</td>\n",
       "      <td>population - entire group you could possibly g...</td>\n",
       "      <td>0.479493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slide</td>\n",
       "      <td>SQL Review.pdf</td>\n",
       "      <td>16</td>\n",
       "      <td>Next Week…\\nNext week will entail:\\n●\\nMonday:...</td>\n",
       "      <td>0.413241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_type                                            file  page  \\\n",
       "0       slide  Introduction to Structured Databases I (1).pdf    62   \n",
       "1       slide                              Advanced SQL I.pdf    43   \n",
       "2       slide     Introduction to Structured Databases II.pdf    42   \n",
       "3       slide              Types of Visualizations Review.pdf    64   \n",
       "4       slide                                  SQL Review.pdf    16   \n",
       "\n",
       "                                                text     score  \n",
       "0  Tuesday\\nOn Tuesday we will review…\\n●\\nWhat i...  0.549009  \n",
       "1  Tuesday\\nSQL + Python\\n●\\nHow do we design a d...  0.531278  \n",
       "2  Wednesday\\nMore SQL Practice!\\n●\\nSQL Leetcode...  0.493887  \n",
       "3  population - entire group you could possibly g...  0.479493  \n",
       "4  Next Week…\\nNext week will entail:\\n●\\nMonday:...  0.413241  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2683c6c074d248a2b03f3c8f50c617d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_type</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lab</td>\n",
       "      <td>w9-class2.ipynb</td>\n",
       "      <td># SQL REVIEW</td>\n",
       "      <td>0.768907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lab</td>\n",
       "      <td>w10-class1.ipynb</td>\n",
       "      <td>\\n    df = pd.read_sql_query(f\"SELECT * FROM {...</td>\n",
       "      <td>0.748725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lab</td>\n",
       "      <td>w7-class3.ipynb</td>\n",
       "      <td>df = pd.read_csv('data.csv')\\n# df = pd.read_e...</td>\n",
       "      <td>0.737325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lab</td>\n",
       "      <td>w10-class1.ipynb</td>\n",
       "      <td>import sqlite3\\nimport pandas as pd</td>\n",
       "      <td>0.718976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lab</td>\n",
       "      <td>w9-class2.ipynb</td>\n",
       "      <td>import sqlite3\\nimport pandas as pd</td>\n",
       "      <td>0.718976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_type              file  \\\n",
       "0         lab   w9-class2.ipynb   \n",
       "1         lab  w10-class1.ipynb   \n",
       "2         lab   w7-class3.ipynb   \n",
       "3         lab  w10-class1.ipynb   \n",
       "4         lab   w9-class2.ipynb   \n",
       "\n",
       "                                                text     score  \n",
       "0                                       # SQL REVIEW  0.768907  \n",
       "1  \\n    df = pd.read_sql_query(f\"SELECT * FROM {...  0.748725  \n",
       "2  df = pd.read_csv('data.csv')\\n# df = pd.read_e...  0.737325  \n",
       "3                import sqlite3\\nimport pandas as pd  0.718976  \n",
       "4                import sqlite3\\nimport pandas as pd  0.718976  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(search_slides(\"SQL joins inner left right\", top_k=5))\n",
    "display(search_labs(\"SQL joins inner left right\", top_k=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
